{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c56bb04",
   "metadata": {},
   "source": [
    "## Section A. Model Complexity and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a76c18",
   "metadata": {},
   "source": [
    "## Question 1 [KNN Regressor, 20 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f13c7",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "673b9eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# used libraries\n",
    "library(reshape2)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4f1f0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_1a  <-  read.csv(\"./Task1A_train.csv\")\n",
    "test_1a  <- read.csv(\"./Task1A_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faac256",
   "metadata": {},
   "source": [
    "### 1. Implement the KNN regressor function:knn(train.data, train.label, test.data, K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a3037a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract x values as single column\n",
    "train_1a_x  <-  train_1a[,1,drop = FALSE]\n",
    "test_1a_x  <-  test_1a[,1,drop = FALSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4c7c41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN function (distance = manhattan)\n",
    "knn <- function(train.data, train.label, test.data, K=K, distance = 'manhattan'){\n",
    "    ## count number of train samples\n",
    "    train.len <- nrow(train.data)\n",
    "    \n",
    "    ## count number of test samples\n",
    "    test.len <- nrow(test.data)\n",
    "    \n",
    "    ## calculate distances between samples\n",
    "    dist <- as.matrix(dist(rbind(test.data, train.data), method= distance))[1:test.len, (test.len+1):(test.len+train.len)]\n",
    "    \n",
    "    ## for each test sample...\n",
    "    for (i in 1:test.len){\n",
    "        ### ...find its K nearest neighbours from training sampels...\n",
    "        nn <- as.data.frame(sort(dist[i,], index.return = TRUE))[1:K,2]\n",
    "        \n",
    "        ###... and calculate the predicted values according to the average\n",
    "        test_1a$y[i]<- sum(train.label[nn])/K\n",
    "        \n",
    "    }\n",
    "    \n",
    "    ## return the predictions as output\n",
    "    return (test_1a$y)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d1b7c",
   "metadata": {},
   "source": [
    "In knn for classification, mode is used to calcculate the predicted labels. In knn regression, average is used to calculate the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fbc80ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.723333333333333</li><li>0.723333333333333</li><li>0.793333333333333</li><li>0.75</li><li>0.853333333333333</li><li>0.823333333333333</li><li>0.916666666666667</li><li>0.916666666666667</li><li>1.05333333333333</li><li>1.10666666666667</li><li>1.17666666666667</li><li>1.29</li><li>1.52333333333333</li><li>1.55</li><li>1.74</li><li>1.63</li><li>1.9</li><li>2.01</li><li>2.4</li><li>2.55</li><li>3.06</li><li>3.36</li><li>3.57</li><li>4.26</li><li>4.74</li><li>5.16</li><li>5.67</li><li>6.06</li><li>6.51</li><li>6.63</li><li>7.23</li><li>7.5</li><li>7.95</li><li>8.52</li><li>9.12</li><li>10.32</li><li>11.19</li><li>12.69</li><li>13.68</li><li>15.03</li><li>15.69</li><li>15.69</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.723333333333333\n",
       "\\item 0.723333333333333\n",
       "\\item 0.793333333333333\n",
       "\\item 0.75\n",
       "\\item 0.853333333333333\n",
       "\\item 0.823333333333333\n",
       "\\item 0.916666666666667\n",
       "\\item 0.916666666666667\n",
       "\\item 1.05333333333333\n",
       "\\item 1.10666666666667\n",
       "\\item 1.17666666666667\n",
       "\\item 1.29\n",
       "\\item 1.52333333333333\n",
       "\\item 1.55\n",
       "\\item 1.74\n",
       "\\item 1.63\n",
       "\\item 1.9\n",
       "\\item 2.01\n",
       "\\item 2.4\n",
       "\\item 2.55\n",
       "\\item 3.06\n",
       "\\item 3.36\n",
       "\\item 3.57\n",
       "\\item 4.26\n",
       "\\item 4.74\n",
       "\\item 5.16\n",
       "\\item 5.67\n",
       "\\item 6.06\n",
       "\\item 6.51\n",
       "\\item 6.63\n",
       "\\item 7.23\n",
       "\\item 7.5\n",
       "\\item 7.95\n",
       "\\item 8.52\n",
       "\\item 9.12\n",
       "\\item 10.32\n",
       "\\item 11.19\n",
       "\\item 12.69\n",
       "\\item 13.68\n",
       "\\item 15.03\n",
       "\\item 15.69\n",
       "\\item 15.69\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.723333333333333\n",
       "2. 0.723333333333333\n",
       "3. 0.793333333333333\n",
       "4. 0.75\n",
       "5. 0.853333333333333\n",
       "6. 0.823333333333333\n",
       "7. 0.916666666666667\n",
       "8. 0.916666666666667\n",
       "9. 1.05333333333333\n",
       "10. 1.10666666666667\n",
       "11. 1.17666666666667\n",
       "12. 1.29\n",
       "13. 1.52333333333333\n",
       "14. 1.55\n",
       "15. 1.74\n",
       "16. 1.63\n",
       "17. 1.9\n",
       "18. 2.01\n",
       "19. 2.4\n",
       "20. 2.55\n",
       "21. 3.06\n",
       "22. 3.36\n",
       "23. 3.57\n",
       "24. 4.26\n",
       "25. 4.74\n",
       "26. 5.16\n",
       "27. 5.67\n",
       "28. 6.06\n",
       "29. 6.51\n",
       "30. 6.63\n",
       "31. 7.23\n",
       "32. 7.5\n",
       "33. 7.95\n",
       "34. 8.52\n",
       "35. 9.12\n",
       "36. 10.32\n",
       "37. 11.19\n",
       "38. 12.69\n",
       "39. 13.68\n",
       "40. 15.03\n",
       "41. 15.69\n",
       "42. 15.69\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  0.7233333  0.7233333  0.7933333  0.7500000  0.8533333  0.8233333\n",
       " [7]  0.9166667  0.9166667  1.0533333  1.1066667  1.1766667  1.2900000\n",
       "[13]  1.5233333  1.5500000  1.7400000  1.6300000  1.9000000  2.0100000\n",
       "[19]  2.4000000  2.5500000  3.0600000  3.3600000  3.5700000  4.2600000\n",
       "[25]  4.7400000  5.1600000  5.6700000  6.0600000  6.5100000  6.6300000\n",
       "[31]  7.2300000  7.5000000  7.9500000  8.5200000  9.1200000 10.3200000\n",
       "[37] 11.1900000 12.6900000 13.6800000 15.0300000 15.6900000 15.6900000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction of knn for test samples when k = 3\n",
    "knn(train_1a_x, train_1a$y, test_1a_x, K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6714db3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# error function: root mean square error\n",
    "RMSE <- function(predicted, target) {\n",
    "    se <- 0\n",
    "    for (i in 1:length(predicted)) {\n",
    "        se <- se + (predicted[i]-target[i])^2\n",
    "    }\n",
    "    return (sqrt(se/length(predicted)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a65d69ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.30554363385303"
      ],
      "text/latex": [
       "1.30554363385303"
      ],
      "text/markdown": [
       "1.30554363385303"
      ],
      "text/plain": [
       "[1] 1.305544"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RMSE for k = 3\n",
    "RMSE(knn(train_1a_x, train_1a$y, test_1a_x, K=3),test_1a$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7465ce74",
   "metadata": {},
   "source": [
    "### 2. Plot the training and the testing errors versus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bf48c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with three columns to store the RMSE results of k from 1 to 35 \n",
    "RMSE_all <- data.frame('K'=1:35, 'train'=rep(0,35), 'test'=rep(0,35))\n",
    "\n",
    "# calculate RMSE for K from 1:35 \n",
    "for (k in 1:35){\n",
    "    # calcuate trainning errors\n",
    "    RMSE_all[k,'train'] <- RMSE(knn(train_1a_x, train_1a$y, test_1a_x, K=k),train_1a$y)\n",
    "    # calculate testing errors\n",
    "    RMSE_all[k,'test'] <-  RMSE(knn(train_1a_x, train_1a$y, test_1a_x, K=k), test_1a$y)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cd026882",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAv8RNTU1oaGh8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\nAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot RMSE of train and test data sets for k = 1:35\n",
    "RMSE_all.m <- melt(RMSE_all, id='K') # reshape for visualization\n",
    "names(RMSE_all.m) <- c('K', 'type', 'error')\n",
    "ggplot(data=RMSE_all.m, aes(x=log(1/K), y=error, color=type)) + geom_line() +\n",
    "       scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +\n",
    "       ggtitle(\"Root mean square error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ed197",
   "metadata": {},
   "source": [
    "### 3. Report  and discuss the optimum value for K in terms of the testing error. \n",
    "\n",
    "The root mean square error plot shows:\n",
    "- Trainning error and test error intersects at around log(1/k) = -2.25.\n",
    "- Before intersection: As k decreases, training error and testing error decreases.\n",
    "- After intersection: As k decreases, training error test error decreases, testing error increases.\n",
    "\n",
    "From the plot shown above, before the intersection of two error lines, both training and testing error is relatively high. The training error decreases after the interesction as testing error increases. \n",
    "In this case, the training error benefits from the decrease of k, which indicates a low bias when k is small. On the other hand, the testing error also benefits from the decrease of k, it decreases as k decreases, although testing error appears to increase after the intersection. In otherwords, the plot shows a bias-variance tradeoff. When the k value is small, the model has a small bias but large variance. If the k value increases, bias increases and variance decreases until the intersection point.\n",
    "\n",
    "In terms of fitting, a low training error may leads to overfitting and a high training error may indicates underfitting. In this case, the large k values before the intersection lead to underfitting and the small k values after the intersection may cause overfitting. Therefore, the optimum value for k should lies around the intersection at log(1/k) = -2.25 on the plot.\n",
    "\n",
    "As the optimum value for k is required to be decided in terms of the testing error, the goal is to minimize the testing error and variance while trying to avoid overfitting or underfitting. Thus, those extreme smaller k values are not suitable as they have high testing errors and low training errors, which may lead to overfitting. Therefore, the optimum value for k should be the intersection point if there is a applicable k value for the intersection point as the testing error at the intersection point is relatively low. Otherwise, the optimum value for k can be a value of k that is closest to the intersection point that has a low testing error and a plausible training error. E.g(If the requirement of the model is to be more generalized, a relatively larger training error is okay.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4df9f4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 35 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>K</th><th scope=col>train</th><th scope=col>test</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>0.1499841</td><td>1.3036067</td></tr>\n",
       "\t<tr><td> 2</td><td>0.3596410</td><td>1.4506300</td></tr>\n",
       "\t<tr><td> 3</td><td>0.3064773</td><td>1.3055436</td></tr>\n",
       "\t<tr><td> 4</td><td>0.3960286</td><td>1.3668279</td></tr>\n",
       "\t<tr><td> 5</td><td>0.4004622</td><td>1.1735642</td></tr>\n",
       "\t<tr><td> 6</td><td>0.5899397</td><td>1.2082640</td></tr>\n",
       "\t<tr><td> 7</td><td>0.6644462</td><td>1.0396384</td></tr>\n",
       "\t<tr><td> 8</td><td>0.8438215</td><td>1.0902330</td></tr>\n",
       "\t<tr><td> 9</td><td>0.9476252</td><td>0.9748048</td></tr>\n",
       "\t<tr><td>10</td><td>1.1328655</td><td>1.0004189</td></tr>\n",
       "\t<tr><td>11</td><td>1.2085654</td><td>0.9533856</td></tr>\n",
       "\t<tr><td>12</td><td>1.3730076</td><td>1.0589985</td></tr>\n",
       "\t<tr><td>13</td><td>1.4515836</td><td>1.0226499</td></tr>\n",
       "\t<tr><td>14</td><td>1.6006794</td><td>1.0944370</td></tr>\n",
       "\t<tr><td>15</td><td>1.6582519</td><td>1.1170263</td></tr>\n",
       "\t<tr><td>16</td><td>1.7734333</td><td>1.2359367</td></tr>\n",
       "\t<tr><td>17</td><td>1.8674236</td><td>1.2514165</td></tr>\n",
       "\t<tr><td>18</td><td>1.9814287</td><td>1.3410052</td></tr>\n",
       "\t<tr><td>19</td><td>2.0578987</td><td>1.3843264</td></tr>\n",
       "\t<tr><td>20</td><td>2.1701364</td><td>1.5031350</td></tr>\n",
       "\t<tr><td>21</td><td>2.2695563</td><td>1.5606849</td></tr>\n",
       "\t<tr><td>22</td><td>2.3778266</td><td>1.6647315</td></tr>\n",
       "\t<tr><td>23</td><td>2.4615500</td><td>1.7267225</td></tr>\n",
       "\t<tr><td>24</td><td>2.5805907</td><td>1.8524404</td></tr>\n",
       "\t<tr><td>25</td><td>2.6660839</td><td>1.9222103</td></tr>\n",
       "\t<tr><td>26</td><td>2.7890145</td><td>2.0467021</td></tr>\n",
       "\t<tr><td>27</td><td>2.8752939</td><td>2.1242978</td></tr>\n",
       "\t<tr><td>28</td><td>2.9921242</td><td>2.2515604</td></tr>\n",
       "\t<tr><td>29</td><td>3.0741754</td><td>2.3271750</td></tr>\n",
       "\t<tr><td>30</td><td>3.1908367</td><td>2.4462846</td></tr>\n",
       "\t<tr><td>31</td><td>3.2765965</td><td>2.5326378</td></tr>\n",
       "\t<tr><td>32</td><td>3.3910528</td><td>2.6540560</td></tr>\n",
       "\t<tr><td>33</td><td>3.4828845</td><td>2.7468771</td></tr>\n",
       "\t<tr><td>34</td><td>3.5930407</td><td>2.8625431</td></tr>\n",
       "\t<tr><td>35</td><td>3.6887694</td><td>2.9628881</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 35 × 3\n",
       "\\begin{tabular}{lll}\n",
       " K & train & test\\\\\n",
       " <int> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & 0.1499841 & 1.3036067\\\\\n",
       "\t  2 & 0.3596410 & 1.4506300\\\\\n",
       "\t  3 & 0.3064773 & 1.3055436\\\\\n",
       "\t  4 & 0.3960286 & 1.3668279\\\\\n",
       "\t  5 & 0.4004622 & 1.1735642\\\\\n",
       "\t  6 & 0.5899397 & 1.2082640\\\\\n",
       "\t  7 & 0.6644462 & 1.0396384\\\\\n",
       "\t  8 & 0.8438215 & 1.0902330\\\\\n",
       "\t  9 & 0.9476252 & 0.9748048\\\\\n",
       "\t 10 & 1.1328655 & 1.0004189\\\\\n",
       "\t 11 & 1.2085654 & 0.9533856\\\\\n",
       "\t 12 & 1.3730076 & 1.0589985\\\\\n",
       "\t 13 & 1.4515836 & 1.0226499\\\\\n",
       "\t 14 & 1.6006794 & 1.0944370\\\\\n",
       "\t 15 & 1.6582519 & 1.1170263\\\\\n",
       "\t 16 & 1.7734333 & 1.2359367\\\\\n",
       "\t 17 & 1.8674236 & 1.2514165\\\\\n",
       "\t 18 & 1.9814287 & 1.3410052\\\\\n",
       "\t 19 & 2.0578987 & 1.3843264\\\\\n",
       "\t 20 & 2.1701364 & 1.5031350\\\\\n",
       "\t 21 & 2.2695563 & 1.5606849\\\\\n",
       "\t 22 & 2.3778266 & 1.6647315\\\\\n",
       "\t 23 & 2.4615500 & 1.7267225\\\\\n",
       "\t 24 & 2.5805907 & 1.8524404\\\\\n",
       "\t 25 & 2.6660839 & 1.9222103\\\\\n",
       "\t 26 & 2.7890145 & 2.0467021\\\\\n",
       "\t 27 & 2.8752939 & 2.1242978\\\\\n",
       "\t 28 & 2.9921242 & 2.2515604\\\\\n",
       "\t 29 & 3.0741754 & 2.3271750\\\\\n",
       "\t 30 & 3.1908367 & 2.4462846\\\\\n",
       "\t 31 & 3.2765965 & 2.5326378\\\\\n",
       "\t 32 & 3.3910528 & 2.6540560\\\\\n",
       "\t 33 & 3.4828845 & 2.7468771\\\\\n",
       "\t 34 & 3.5930407 & 2.8625431\\\\\n",
       "\t 35 & 3.6887694 & 2.9628881\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 35 × 3\n",
       "\n",
       "| K &lt;int&gt; | train &lt;dbl&gt; | test &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "|  1 | 0.1499841 | 1.3036067 |\n",
       "|  2 | 0.3596410 | 1.4506300 |\n",
       "|  3 | 0.3064773 | 1.3055436 |\n",
       "|  4 | 0.3960286 | 1.3668279 |\n",
       "|  5 | 0.4004622 | 1.1735642 |\n",
       "|  6 | 0.5899397 | 1.2082640 |\n",
       "|  7 | 0.6644462 | 1.0396384 |\n",
       "|  8 | 0.8438215 | 1.0902330 |\n",
       "|  9 | 0.9476252 | 0.9748048 |\n",
       "| 10 | 1.1328655 | 1.0004189 |\n",
       "| 11 | 1.2085654 | 0.9533856 |\n",
       "| 12 | 1.3730076 | 1.0589985 |\n",
       "| 13 | 1.4515836 | 1.0226499 |\n",
       "| 14 | 1.6006794 | 1.0944370 |\n",
       "| 15 | 1.6582519 | 1.1170263 |\n",
       "| 16 | 1.7734333 | 1.2359367 |\n",
       "| 17 | 1.8674236 | 1.2514165 |\n",
       "| 18 | 1.9814287 | 1.3410052 |\n",
       "| 19 | 2.0578987 | 1.3843264 |\n",
       "| 20 | 2.1701364 | 1.5031350 |\n",
       "| 21 | 2.2695563 | 1.5606849 |\n",
       "| 22 | 2.3778266 | 1.6647315 |\n",
       "| 23 | 2.4615500 | 1.7267225 |\n",
       "| 24 | 2.5805907 | 1.8524404 |\n",
       "| 25 | 2.6660839 | 1.9222103 |\n",
       "| 26 | 2.7890145 | 2.0467021 |\n",
       "| 27 | 2.8752939 | 2.1242978 |\n",
       "| 28 | 2.9921242 | 2.2515604 |\n",
       "| 29 | 3.0741754 | 2.3271750 |\n",
       "| 30 | 3.1908367 | 2.4462846 |\n",
       "| 31 | 3.2765965 | 2.5326378 |\n",
       "| 32 | 3.3910528 | 2.6540560 |\n",
       "| 33 | 3.4828845 | 2.7468771 |\n",
       "| 34 | 3.5930407 | 2.8625431 |\n",
       "| 35 | 3.6887694 | 2.9628881 |\n",
       "\n"
      ],
      "text/plain": [
       "   K  train     test     \n",
       "1   1 0.1499841 1.3036067\n",
       "2   2 0.3596410 1.4506300\n",
       "3   3 0.3064773 1.3055436\n",
       "4   4 0.3960286 1.3668279\n",
       "5   5 0.4004622 1.1735642\n",
       "6   6 0.5899397 1.2082640\n",
       "7   7 0.6644462 1.0396384\n",
       "8   8 0.8438215 1.0902330\n",
       "9   9 0.9476252 0.9748048\n",
       "10 10 1.1328655 1.0004189\n",
       "11 11 1.2085654 0.9533856\n",
       "12 12 1.3730076 1.0589985\n",
       "13 13 1.4515836 1.0226499\n",
       "14 14 1.6006794 1.0944370\n",
       "15 15 1.6582519 1.1170263\n",
       "16 16 1.7734333 1.2359367\n",
       "17 17 1.8674236 1.2514165\n",
       "18 18 1.9814287 1.3410052\n",
       "19 19 2.0578987 1.3843264\n",
       "20 20 2.1701364 1.5031350\n",
       "21 21 2.2695563 1.5606849\n",
       "22 22 2.3778266 1.6647315\n",
       "23 23 2.4615500 1.7267225\n",
       "24 24 2.5805907 1.8524404\n",
       "25 25 2.6660839 1.9222103\n",
       "26 26 2.7890145 2.0467021\n",
       "27 27 2.8752939 2.1242978\n",
       "28 28 2.9921242 2.2515604\n",
       "29 29 3.0741754 2.3271750\n",
       "30 30 3.1908367 2.4462846\n",
       "31 31 3.2765965 2.5326378\n",
       "32 32 3.3910528 2.6540560\n",
       "33 33 3.4828845 2.7468771\n",
       "34 34 3.5930407 2.8625431\n",
       "35 35 3.6887694 2.9628881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# recall the RMSE table\n",
    "RMSE_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f9b8b",
   "metadata": {},
   "source": [
    "From the table the best k value matches the requirements is: k = 9, which is the intersection point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
